{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bilateral facial symmetry (LL RR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "#import argparse\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "#import os\n",
    "import glob\n",
    "#import time\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from pandas import DataFrame\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "#from keras.models import load_model\n",
    "#from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.4\n",
      "1.17.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "print(matplotlib.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading models for face detection and set defaults\n",
    "net = cv2.dnn.readNetFromCaffe('deploy.prototxt.txt', 'res10_300x300_ssd_iter_140000.caffemodel')\n",
    "camera = cv2.VideoCapture(0)\n",
    "main_option=1\n",
    "# initialize dlib's face detector (HOG-based) and then create the facial landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beginning GUI\n",
    "gui = Tk(className=' LLRR_Facial_Similarity')\n",
    "# set window size and position it at center of screen\n",
    "windowWidth=800\n",
    "windowHeight=400\n",
    "positionRight = int(gui.winfo_screenwidth()/2 - windowWidth/2)\n",
    "positionDown = int(gui.winfo_screenheight()/2 - windowHeight/2)\n",
    "gui.geometry(\"{}x{}+{}+{}\".format(windowWidth,windowHeight,positionRight,positionDown))\n",
    "xx=gui.winfo_screenwidth()/2\n",
    "\n",
    "w = Label(gui, text=\"\\nWelcome! \\n\\nThis tool helps to analyze similarity of dynamic composite faces\\n\",font=(\"Helvetica\", 15))\n",
    "w.pack()\n",
    "v = IntVar()# identifies which one is selected\n",
    "\n",
    "Label(gui, text=\"Select one of the following ways of capturing a video:\",justify = LEFT,padx = 20).pack()\n",
    "Radiobutton(gui, text=\"Real-time Analysis via webcam\",padx = 20, variable=v, value=1).pack(anchor=W)\n",
    "Radiobutton(gui, text=\"Analysis of a pre-recorded video\",padx = 20, variable=v, value=2).pack(anchor=W)\n",
    "\n",
    "def helloCallBack():\n",
    "    global camera\n",
    "    global main_option\n",
    "    if v.get()==1:\n",
    "        gui.destroy()\n",
    "        tempp=Tk(className=' Note')\n",
    "        # set window size and position it at center of screen\n",
    "        winWidth=400\n",
    "        winHeight=200\n",
    "        posRight = int(tempp.winfo_screenwidth()/2 - winWidth/2)\n",
    "        posDown = int(tempp.winfo_screenheight()/2 - winHeight/2)\n",
    "        tempp.geometry(\"{}x{}+{}+{}\".format(winWidth,winHeight,posRight,posDown))\n",
    "        Label(tempp,text=\"\\nWebCam Callibration Complete\\n\",font=(\"Helvetica\", 10)).pack()\n",
    "        Label(tempp,text=\"Press the button below to begin Real-time streaming!\",font=(\"Helvetica\", 10)).pack()\n",
    "        Label(tempp,text=\"(Press q to stop recording anytime you wish)\\n\",font=(\"Helvetica\", 10)).pack()\n",
    "        B1 = Button(tempp, text=\"START\", command = tempp.destroy)\n",
    "        B1.pack()\n",
    "        tempp.mainloop()\n",
    "        \n",
    "    if v.get()==2:\n",
    "        root = Tk(className=' Choose Video...')\n",
    "        root.geometry(\"500x100+10+10\")#width x heigth\n",
    "        w1 = Label(root, text=\"\\nBrowse your system for the Test Video...\",font=(\"Helvetica\", 15))\n",
    "        w1.pack()\n",
    "        root.filename =  filedialog.askopenfilename(initialdir = \"/\",title = \"Select file\",filetypes = ((\"All files\",\"*.*\"),(\"jpeg files\",\"*.jpg\")))\n",
    "        test_video_path = root.filename\n",
    "        root.destroy()\n",
    "        \n",
    "        camera = cv2.VideoCapture(test_video_path)# from the pre recorded video in path\n",
    "        main_option=2\n",
    "        gui.destroy()\n",
    "        \n",
    "        tempp=Tk(className=' Note')\n",
    "        # set window size and position it at center of screen\n",
    "        winWidth=400\n",
    "        winHeight=200\n",
    "        posRight = int(tempp.winfo_screenwidth()/2 - winWidth/2)\n",
    "        posDown = int(tempp.winfo_screenheight()/2 - winHeight/2)\n",
    "        tempp.geometry(\"{}x{}+{}+{}\".format(winWidth,winHeight,posRight,posDown))\n",
    "        Label(tempp,text=\"\\nPreliminary Callibration Complete\\n\",font=(\"Helvetica\", 10)).pack()\n",
    "        Label(tempp,text=\"Press the button below to begin video analysis!\",font=(\"Helvetica\", 10)).pack()\n",
    "        Label(tempp,text=\"(Press q to stop anytime you wish)\\n\",font=(\"Helvetica\", 10)).pack()\n",
    "        B1 = Button(tempp, text=\"START\", command = tempp.destroy)\n",
    "        B1.pack()\n",
    "        tempp.mainloop()\n",
    "\n",
    "\n",
    "button = Button(gui, text='Confirm', width=25, command=helloCallBack)\n",
    "button.pack()\n",
    "\n",
    "gui.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting video streaming\n",
    "cv2.namedWindow('TestVideo')\n",
    "cv2.namedWindow('LL RR composites')\n",
    "cv2.moveWindow('TestVideo', int(xx-400),75)# width wise centerscreen\n",
    "tlt = 3 # number of pixels of tilt allowance (allow if <tlt)\n",
    "t_pass = []\n",
    "frms=0\n",
    "sim_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while camera.isOpened():\n",
    "    ret, frame = camera.read()# by default the webcam reads at around 30fps, can be changed by other codes\n",
    "    if ret==False:\n",
    "        break\n",
    "    #reading the frame\n",
    "    frame = imutils.resize(frame,width=800)\n",
    "    if main_option==1:\n",
    "        frame = cv2.flip(frame, 1)\n",
    "    frameClone = frame.copy()\n",
    "    frameClone = cv2.putText(frameClone, 'Press Q to stop',(500, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "    t_pass.append(frms)\n",
    "    sim_list.append(-0.1)\n",
    "    frms = frms+1\n",
    "        \n",
    "    ###-------------begin finding 68 facial landmarks using dlib\n",
    "\n",
    "    ## this section checks for correct facial alignment\n",
    "    gray_frame = cv2.cvtColor(frameClone, cv2.COLOR_BGR2GRAY)\n",
    "    # detect faces in the grayscale image (dlib object for dlib shape prediction)\n",
    "    rects = detector(gray_frame, 1)\n",
    "    if len(rects)!=0:\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy array\n",
    "        shape = predictor(gray_frame, rects[0])\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        # loop over the (x, y)-coordinates for the facial landmarks\n",
    "        # and draw them on the image\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(frameClone, (x, y), 1, (0, 0, 255), -1)\n",
    "\n",
    "        ### ADD CODE for checking alignment\n",
    "        ylj = shape[0][1] # y coordinate of left jaw\n",
    "        yrj = shape[16][1] # y coordinate of right jaw\n",
    "        xtn = shape[27][0] # x coordinate of top of nose\n",
    "        xbn = shape[30][0] # x coordinate of bottom of nose\n",
    "\n",
    "        if abs(ylj-yrj)>=tlt or abs(xtn-xbn)>=tlt:\n",
    "            continue\n",
    "        \n",
    "        # convert dlib's rectangle to a OpenCV-style bounding box [i.e., (x, y, w, h)], then draw the face bounding box\n",
    "        (x, y, w, h) = face_utils.rect_to_bb(rects[0])\n",
    "        cv2.rectangle(frameClone, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "        \n",
    "        ###-------------end finding 68 facial landmarks using dlib\n",
    "        \n",
    "        ### using CNN : (if face is well aligned)\n",
    "        # grab the frame dimensions and convert it to a blob\n",
    "        (h, w) = frame.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,(300, 300), (104.0, 177.0, 123.0))\n",
    "        # pass the blob through the network and obtain the detections and predictions\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        #if detections[0, 0, 0, 2] > 0.75: # 75% confidence of a face existing in the frame\n",
    "        # compute the (x, y)-coordinates of the bounding box for the object\n",
    "        box = detections[0, 0, 0, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "        (fX, fY, fW, fH) = (startX, startY, endX-startX, endY-startY)\n",
    "        cv2.rectangle(frameClone, (fX, fY), (fX + fW, fY + fH),(255, 0, 0), 1)\n",
    "        \n",
    "        crop_face = frame[startY:endY, startX:endX]\n",
    "        #----------------------LL RR--------------\n",
    "        (hh,ww,dd) = crop_face.shape\n",
    "        if ww%2==0:\n",
    "            ww1=ww//2-1\n",
    "        else:\n",
    "            ww1=ww//2\n",
    "        flipHorizontal = cv2.flip(crop_face, 1)\n",
    "        img1 = crop_face[:,0:ww1]\n",
    "        img2 = flipHorizontal[:,ww1+1:]\n",
    "        LL = np.concatenate((img1, img2), axis=1)\n",
    "        img1 = flipHorizontal[:,0:ww1]\n",
    "        img2 = crop_face[:,ww1+1:]\n",
    "        RR = np.concatenate((img1, img2), axis=1)\n",
    "        llrr = np.concatenate((LL,RR),axis=0)\n",
    "        cv2.imshow('LL RR composites',llrr)\n",
    "        \n",
    "        # calculate similarity index (0-1) (least - identical)\n",
    "        sim_index = ssim(cv2.cvtColor(LL, cv2.COLOR_BGR2GRAY), cv2.cvtColor(RR, cv2.COLOR_BGR2GRAY))\n",
    "        sim_list[frms-1] = sim_index\n",
    "    \n",
    "    cv2.imshow('TestVideo', frameClone)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):# press q to stop\n",
    "        break\n",
    "        \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_passn =np.array(t_pass)\n",
    "t_passn =100*t_passn/t_pass[-1]\n",
    "sim_listn = 100*np.array(sim_list) # percentage\n",
    "\n",
    "data = {'Time': t_passn,\n",
    "         'Similarity_index': sim_listn\n",
    "        }\n",
    "df2 = DataFrame(data,columns=['Time','Similarity_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Tk(className=' Final Results')\n",
    "# set window size and position it at center of screen\n",
    "#winWidth=900\n",
    "#winHeight=550\n",
    "#posRight = int(res.winfo_screenwidth()/2 - winWidth/2)\n",
    "#posDown = int(res.winfo_screenheight()/2 - winHeight/2)\n",
    "#res.geometry(\"{}x{}+{}+{}\".format(winWidth,winHeight,posRight,posDown))\n",
    "\n",
    "figure2 = plt.Figure(figsize=(8,6), dpi=100)\n",
    "ax2 = figure2.add_subplot(111)\n",
    "line2 = FigureCanvasTkAgg(figure2, res)# using toplevel for graph\n",
    "line2.get_tk_widget().pack(side=tk.LEFT, fill=tk.BOTH)\n",
    "df2 = df2[['Time','Similarity_index']].groupby('Time').sum()\n",
    "df2.plot(kind='line', legend=True, ax=ax2,fontsize=10)\n",
    "ax2.set_title('Variation of Similarity index over captured frames')\n",
    "\n",
    "res.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FigureCanvasTkAgg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-513013ac280d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[0mfigure2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[0max2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfigure2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m111\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m \u001b[0mline2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFigureCanvasTkAgg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# using toplevel for graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[0mline2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tk_widget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mside\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLEFT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBOTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Similarity_index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'FigureCanvasTkAgg' is not defined"
     ]
    }
   ],
   "source": [
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "#import os\n",
    "import glob\n",
    "#import time\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from pandas import DataFrame\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "\n",
    "# loading models for face detection and set defaults\n",
    "net = cv2.dnn.readNetFromCaffe('deploy.prototxt.txt', 'res10_300x300_ssd_iter_140000.caffemodel')\n",
    "camera = cv2.VideoCapture(0)\n",
    "main_option=1\n",
    "# initialize dlib's face detector (HOG-based) and then create the facial landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "#Beginning GUI\n",
    "gui = Tk(className=' LLRR_Facial_Similarity')\n",
    "# set window size and position it at center of screen\n",
    "windowWidth=800\n",
    "windowHeight=400\n",
    "positionRight = int(gui.winfo_screenwidth()/2 - windowWidth/2)\n",
    "positionDown = int(gui.winfo_screenheight()/2 - windowHeight/2)\n",
    "gui.geometry(\"{}x{}+{}+{}\".format(windowWidth,windowHeight,positionRight,positionDown))\n",
    "xx=gui.winfo_screenwidth()/2\n",
    "\n",
    "w = Label(gui, text=\"\\nWelcome! \\n\\nThis tool helps to analyze similarity of dynamic composite faces\\n\",font=(\"Helvetica\", 15))\n",
    "w.pack()\n",
    "v = IntVar()# identifies which one is selected\n",
    "\n",
    "Label(gui, text=\"Select one of the following ways of capturing a video:\",justify = LEFT,padx = 20).pack()\n",
    "Radiobutton(gui, text=\"Real-time Analysis via webcam\",padx = 20, variable=v, value=1).pack(anchor=W)\n",
    "Radiobutton(gui, text=\"Analysis of a pre-recorded video\",padx = 20, variable=v, value=2).pack(anchor=W)\n",
    "\n",
    "def helloCallBack():\n",
    "    global camera\n",
    "    global main_option\n",
    "    if v.get()==1:\n",
    "        gui.destroy()\n",
    "        tempp=Tk(className=' Note')\n",
    "        # set window size and position it at center of screen\n",
    "        winWidth=400\n",
    "        winHeight=200\n",
    "        posRight = int(tempp.winfo_screenwidth()/2 - winWidth/2)\n",
    "        posDown = int(tempp.winfo_screenheight()/2 - winHeight/2)\n",
    "        tempp.geometry(\"{}x{}+{}+{}\".format(winWidth,winHeight,posRight,posDown))\n",
    "        Label(tempp,text=\"\\nWebCam Callibration Complete\\n\",font=(\"Helvetica\", 10)).pack()\n",
    "        Label(tempp,text=\"Press the button below to begin Real-time streaming!\",font=(\"Helvetica\", 10)).pack()\n",
    "        Label(tempp,text=\"(Press q to stop recording anytime you wish)\\n\",font=(\"Helvetica\", 10)).pack()\n",
    "        B1 = Button(tempp, text=\"START\", command = tempp.destroy)\n",
    "        B1.pack()\n",
    "        tempp.mainloop()\n",
    "        \n",
    "    if v.get()==2:\n",
    "        root = Tk(className=' Choose Video...')\n",
    "        root.geometry(\"500x100+10+10\")#width x heigth\n",
    "        w1 = Label(root, text=\"\\nBrowse your system for the Test Video...\",font=(\"Helvetica\", 15))\n",
    "        w1.pack()\n",
    "        root.filename =  filedialog.askopenfilename(initialdir = \"/\",title = \"Select file\",filetypes = ((\"All files\",\"*.*\"),(\"jpeg files\",\"*.jpg\")))\n",
    "        test_video_path = root.filename\n",
    "        root.destroy()\n",
    "        \n",
    "        camera = cv2.VideoCapture(test_video_path)# from the pre recorded video in path\n",
    "        main_option=2\n",
    "        gui.destroy()\n",
    "        \n",
    "        tempp=Tk(className=' Note')\n",
    "        # set window size and position it at center of screen\n",
    "        winWidth=400\n",
    "        winHeight=200\n",
    "        posRight = int(tempp.winfo_screenwidth()/2 - winWidth/2)\n",
    "        posDown = int(tempp.winfo_screenheight()/2 - winHeight/2)\n",
    "        tempp.geometry(\"{}x{}+{}+{}\".format(winWidth,winHeight,posRight,posDown))\n",
    "        Label(tempp,text=\"\\nPreliminary Callibration Complete\\n\",font=(\"Helvetica\", 10)).pack()\n",
    "        Label(tempp,text=\"Press the button below to begin video analysis!\",font=(\"Helvetica\", 10)).pack()\n",
    "        Label(tempp,text=\"(Press q to stop anytime you wish)\\n\",font=(\"Helvetica\", 10)).pack()\n",
    "        B1 = Button(tempp, text=\"START\", command = tempp.destroy)\n",
    "        B1.pack()\n",
    "        tempp.mainloop()\n",
    "\n",
    "\n",
    "button = Button(gui, text='Confirm', width=25, command=helloCallBack)\n",
    "button.pack()\n",
    "\n",
    "gui.mainloop()\n",
    "\n",
    "# starting video streaming\n",
    "cv2.namedWindow('TestVideo')\n",
    "cv2.namedWindow('LL RR composites')\n",
    "cv2.moveWindow('TestVideo', int(xx-400),75)# width wise centerscreen\n",
    "tlt = 3 # number of pixels of tilt allowance (allow if <tlt)\n",
    "t_pass = []\n",
    "frms=0\n",
    "sim_list = []\n",
    "\n",
    "while camera.isOpened():\n",
    "    ret, frame = camera.read()# by default the webcam reads at around 30fps, can be changed by other codes\n",
    "    if ret==False:\n",
    "        break\n",
    "    #reading the frame\n",
    "    frame = imutils.resize(frame,width=800)\n",
    "    if main_option==1:\n",
    "        frame = cv2.flip(frame, 1)\n",
    "    frameClone = frame.copy()\n",
    "    frameClone = cv2.putText(frameClone, 'Press Q to stop',(500, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "    t_pass.append(frms)\n",
    "    sim_list.append(-0.1)\n",
    "    frms = frms+1\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):# press q to stop\n",
    "        break\n",
    "        \n",
    "    ###-------------begin finding 68 facial landmarks using dlib\n",
    "\n",
    "    ## this section checks for correct facial alignment\n",
    "    gray_frame = cv2.cvtColor(frameClone, cv2.COLOR_BGR2GRAY)\n",
    "    # detect faces in the grayscale image (dlib object for dlib shape prediction)\n",
    "    rects = detector(gray_frame, 1)\n",
    "    if len(rects)!=0:\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy array\n",
    "        shape = predictor(gray_frame, rects[0])\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        # loop over the (x, y)-coordinates for the facial landmarks\n",
    "        # and draw them on the image\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(frameClone, (x, y), 1, (0, 0, 255), -1)\n",
    "\n",
    "        ### ADD CODE for checking alignment\n",
    "        ylj = shape[0][1] # y coordinate of left jaw\n",
    "        yrj = shape[16][1] # y coordinate of right jaw\n",
    "        xtn = shape[27][0] # x coordinate of top of nose\n",
    "        xbn = shape[30][0] # x coordinate of bottom of nose\n",
    "\n",
    "        if abs(ylj-yrj)>=tlt or abs(xtn-xbn)>=tlt:\n",
    "            cv2.imshow('TestVideo', frameClone)\n",
    "            continue\n",
    "        \n",
    "        # convert dlib's rectangle to a OpenCV-style bounding box [i.e., (x, y, w, h)], then draw the face bounding box\n",
    "        (x, y, w, h) = face_utils.rect_to_bb(rects[0])\n",
    "        cv2.rectangle(frameClone, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "        \n",
    "        ###-------------end finding 68 facial landmarks using dlib\n",
    "        \n",
    "        ### using CNN : (if face is well aligned)\n",
    "        # grab the frame dimensions and convert it to a blob\n",
    "        (h, w) = frame.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,(300, 300), (104.0, 177.0, 123.0))\n",
    "        # pass the blob through the network and obtain the detections and predictions\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        #if detections[0, 0, 0, 2] > 0.75: # 75% confidence of a face existing in the frame\n",
    "        # compute the (x, y)-coordinates of the bounding box for the object\n",
    "        box = detections[0, 0, 0, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "        (fX, fY, fW, fH) = (startX, startY, endX-startX, endY-startY)\n",
    "        cv2.rectangle(frameClone, (fX, fY), (fX + fW, fY + fH),(255, 0, 0), 1)\n",
    "        \n",
    "        crop_face = frame[startY:endY, startX:endX]\n",
    "        #----------------------LL RR--------------\n",
    "        (hh,ww,dd) = crop_face.shape\n",
    "        if ww%2==0:\n",
    "            ww1=ww//2-1\n",
    "        else:\n",
    "            ww1=ww//2\n",
    "        flipHorizontal = cv2.flip(crop_face, 1)\n",
    "        img1 = crop_face[:,0:ww1]\n",
    "        img2 = flipHorizontal[:,ww1+1:]\n",
    "        LL = np.concatenate((img1, img2), axis=1)\n",
    "        img1 = flipHorizontal[:,0:ww1]\n",
    "        img2 = crop_face[:,ww1+1:]\n",
    "        RR = np.concatenate((img1, img2), axis=1)\n",
    "        llrr = np.concatenate((LL,RR),axis=0)\n",
    "        cv2.imshow('LL RR composites',llrr)\n",
    "        \n",
    "        # calculate similarity index (0-1) (least - identical)\n",
    "        sim_index = ssim(cv2.cvtColor(LL, cv2.COLOR_BGR2GRAY), cv2.cvtColor(RR, cv2.COLOR_BGR2GRAY))\n",
    "        sim_list[frms-1] = sim_index\n",
    "        \n",
    "        cv2.imshow('TestVideo', frameClone)\n",
    "    \n",
    "    else:\n",
    "        cv2.imshow('TestVideo', frameClone)\n",
    "        continue\n",
    "        \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "t_passn =np.array(t_pass)\n",
    "t_passn =100*t_passn/t_pass[-1]\n",
    "sim_listn = 100*np.array(sim_list) # percentage\n",
    "\n",
    "data = {'Time': t_passn,\n",
    "         'Similarity_index': sim_listn\n",
    "        }\n",
    "df2 = DataFrame(data,columns=['Time','Similarity_index'])\n",
    "\n",
    "res = Tk(className=' Final Results')\n",
    "# set window size and position it at center of screen\n",
    "#winWidth=900\n",
    "#winHeight=550\n",
    "#posRight = int(res.winfo_screenwidth()/2 - winWidth/2)\n",
    "#posDown = int(res.winfo_screenheight()/2 - winHeight/2)\n",
    "#res.geometry(\"{}x{}+{}+{}\".format(winWidth,winHeight,posRight,posDown))\n",
    "\n",
    "figure2 = plt.Figure(figsize=(8,6), dpi=100)\n",
    "ax2 = figure2.add_subplot(111)\n",
    "line2 = FigureCanvasTkAgg(figure2, res)# using toplevel for graph\n",
    "line2.get_tk_widget().pack(side=tk.LEFT, fill=tk.BOTH)\n",
    "df2 = df2[['Time','Similarity_index']].groupby('Time').sum()\n",
    "df2.plot(kind='line', legend=True, ax=ax2,fontsize=10)\n",
    "ax2.set_title('Variation of Similarity index over captured frames')\n",
    "\n",
    "res.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
